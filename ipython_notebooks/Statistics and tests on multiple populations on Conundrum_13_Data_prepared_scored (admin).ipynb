{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis and tests (Multiple Populations) on Conundrum_13_Data_prepared_scored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate analysis is perhaps the simplest form of statistical analysis. The key fact is that only one variable is involved.\n",
    "\n",
    "Bivariate analysis involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them.\n",
    "\n",
    "Hypothesis tests are used in determining what outcomes of a study would lead to a rejection of the null hypothesis for a pre-specified level of significance.\n",
    "\n",
    "* [Setup and loading the data](#setup)\n",
    "* [Preprocessing of the data](#preprocessing)\n",
    "* [Statistical analysis and vizualisation](#general)\n",
    "* [Single population tests](#tests_single)\n",
    "* [Two-population tests](#tests_two_pop)\n",
    "\n",
    "<center><strong>Select Cell > Run All to execute the whole analysis</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and dataset loading <a id=\"setup\" /> \n",
    "\n",
    "First of all, let's load the libraries that we'll use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataiku                               # Access to Dataiku datasets\n",
    "import pandas as pd, numpy as np             # Data manipulation \n",
    "from matplotlib import pyplot as plt         # Graphing\n",
    "import seaborn as sns                        # Graphing\n",
    "#sns.set(style=\"white\")                       # Tuning the style of charts\n",
    "import warnings                              # Disable some warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "from scipy import stats                      # Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is now to load the dataset and put aside the three main types of columns:\n",
    "\n",
    "* Numerics\n",
    "* Categorical\n",
    "* Dates\n",
    "\n",
    "Statistical analysis requires having the data in memory, we are only going to load a sample of the data. Modify the following cell to change the size of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_limit = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a DSS dataset as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a handle on the dataset\n",
    "mydataset = dataiku.Dataset(\"Conundrum_13_Data_prepared_scored\")\n",
    "\n",
    "# Load the first lines.\n",
    "# You can also load random samples, limit yourself to some columns, or only load\n",
    "# data matching some filters.\n",
    "#\n",
    "# Please refer to the Dataiku Python API documentation for more information\n",
    "df = mydataset.get_dataframe(limit = dataset_limit)\n",
    "\n",
    "# Due to a bug in the current release (0.7) of seaborn we will need to strip non ASCII characters from columns...\n",
    "import unicodedata\n",
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "df.columns = [strip_accents(col) for col in df.columns]\n",
    "\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Get the column names\n",
    "numerical_columns = list(df.select_dtypes(include=[np.number]).columns)\n",
    "categorical_columns = list(df.select_dtypes(include=[object]).columns)\n",
    "date_columns = list(df.select_dtypes(include=['<M8[ns]']).columns)\n",
    "\n",
    "# Print a quick summary of what we just loaded\n",
    "print \"Loaded dataset\"\n",
    "print \"   Rows: %s\" % df.shape[0]\n",
    "print \"   Columns: %s (%s num, %s cat, %s date)\" % (df.shape[1], \n",
    "                                                    len(numerical_columns), len(categorical_columns),\n",
    "                                                    len(date_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data <a id=\"preprocessing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the values are in the first numerical column, and population labels in the first categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_col = numerical_columns[0]\n",
    "population_col = categorical_columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following lines to take control on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected value and population columns are 'Age' and 'Name'\n"
     ]
    }
   ],
   "source": [
    "#value_col = u'my_value_column'\n",
    "#population_col = u'my_population_column'\n",
    "print \"Selected value and population columns are '%s' and '%s'\" % (value_col, population_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impute missing values in the value column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling value column 'Age' with 26.7919\n"
     ]
    }
   ],
   "source": [
    "# Use mean for numerical features\n",
    "v = df[value_col].mean()\n",
    "if np.isnan(v):\n",
    "    v = 0\n",
    "print \"Filling value column '%s' with %s\" % (value_col, v)\n",
    "df[value_col] = df[value_col].fillna(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the list of population names from the dataset and plot the count for each value.\n",
    "\n",
    "We also create a dataset containing only values with more than 10 samples, for plotting histograms in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = [ [item, df[df[population_col] == item][value_col]] for item in df[population_col].value_counts().index]\n",
    "pop_mult_val = df[population_col].value_counts()[df[population_col].value_counts() > 10]\n",
    "df_mult_val = df[[value_col, population_col]][df[population_col].isin(pop_mult_val.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(121)\n",
    "sns.countplot(y=population_col, data=df.sort_values(population_col))\n",
    "plt.subplot(122)\n",
    "df[population_col].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis and vizualisation <a id=\"general\" /a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General statistics\n",
    "Number of records, mean, standard deviation, minimal value, quartiles, maximum value, mode, variance, skewness and kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_list = []\n",
    "cols = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'mode', 'var', 'skew', 'kurtosis']\n",
    "for pop in populations:\n",
    "    stats_list.append([el for el in pop[1].describe()] + [NaN if pop[1].mode().empty else pop[1].mode()[0],pop[1].var(),pop[1].skew(),pop[1].kurtosis()])\n",
    "stats_df = pd.DataFrame(stats_list, columns=cols, index=[pop[0] for pop in populations])\n",
    "\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use plots to visualize statistics about your data\n",
    "\n",
    "You can try: 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'mode', 'var', 'skew', 'kurtosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "stats_df['count'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram & Distplot\n",
    "Histograms let you see the number of occurrences in your value column for each population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df[[value_col, population_col]], col=population_col, col_wrap=4)\n",
    "g.map(plt.hist, value_col);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distplots combine an histogram with a kernel density estimation. We plot these only for populations with more than 10 occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_mult_val, col=population_col, col_wrap=4)\n",
    "g.map(sns.distplot, value_col);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms and distplots for all populations can also be displayed on the same graph. Hard to read if you have many populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Histograms of all populations\")\n",
    "for pop in pop_mult_val.index:\n",
    "    plt.hist(df_mult_val[df_mult_val[population_col]==pop][value_col], label =  pop)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Distplots of all populations\")\n",
    "for pop in pop_mult_val.index:\n",
    "    sns.distplot(df_mult_val[df_mult_val[population_col]==pop][value_col], kde_kws={\"label\": pop})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way of representing statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles, with a vertical line inside to indicate the median value. The lower and upper quartiles are shown as horizontal lines either side of the rectangle. Plotted only for populations with more than 10 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(x=value_col, y=population_col, data=df_mult_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plot is similar to box plots, except that they also show the probability density of the data at different values. Violin plots include a marker for the median of the data and a box indicating the interquartile range, as in standard box plots. Overlaid on this box plot is a kernel density estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.violinplot(x=value_col, y=population_col, data=df_mult_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter value plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letter value plots are an improvement upon boxplots for large datasets.\n",
    "\n",
    "They display the median and the quartiles, like a standard box plot, but will also draw boxes for subsequent \"eights\", \"sixteenth\" etc... which are generically called letter values.\n",
    "\n",
    "A cut off condition will leave a reasonable number of outliers out of the final boxes, helping you spot them easily.\n",
    "\n",
    "Letter valuer plot give a good sense of the distribution of data, and of its skewness.\n",
    "\n",
    "Plotted only for populations with more than 10 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.lvplot(x=value_col, y=population_col, data=df_mult_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical testing <a id=\"tests\" /a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical tests will be computed by default for the two largest populations found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[pop_name_1, df_pop_1], [pop_name_2, df_pop_2]] = [ pop for pop in populations[0:2]]\n",
    "print \"Series '%s' has %s and series '%s' has %s records\" % (pop_name_1, df_pop_1.count(), pop_name_2, df_pop_2.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** For a given significance level (e.g. 0.05), if the resulting p-value is smaller (p < 0.05), the null hypothesis is rejected. Otherwise (p â‰¥ 0.05) it cannot be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your confidence threshold here, default is 0.05\n",
    "confidence = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_results(confidence, pvalue, message, population_name):\n",
    "    if pvalue < confidence:\n",
    "        print \"The hypothesis of \" + message + \" for \"+ population_name + \" is rejected with pvalue %s (smaller than %s)\" % (pvalue, confidence)\n",
    "    else:\n",
    "        print \"The hypothesis of \" + message + \" for \"+ population_name + \" can not be rejected, pvalue was %s (greater than %s)\" % (pvalue, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single population tests <a id=\"tests_single\" /a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of fit with a normal law: Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null-hypothesis of this test is that the population is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_1 = stats.shapiro(df_pop_1)[1]\n",
    "pvalue_2 = stats.shapiro(df_pop_2)[1]\n",
    "test = 'normal distribution'\n",
    "analyse_results(confidence, pvalue_1, test, pop_name_1)\n",
    "analyse_results(confidence, pvalue_2, test, pop_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for the average value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null-hypothesis of this test is that the population has the specified mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mean you ant to test for here\n",
    "tested_mean = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_1 = stats.ttest_1samp(df_pop_1, tested_mean).pvalue\n",
    "pvalue_2 = stats.ttest_1samp(df_pop_2, tested_mean).pvalue\n",
    "test = 'mean=%s' % (tested_mean)\n",
    "analyse_results(confidence, pvalue_1, test, pop_name_1)\n",
    "analyse_results(confidence, pvalue_2, test, pop_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two - population tests <a id=\"tests_two_pop\" /a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null-hypothesis of this test is that both populations have the same average, variance is assumed to be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = stats.ttest_ind(df_pop_1, df_pop_2).pvalue\n",
    "test = 'equal averages'\n",
    "analyse_results(confidence, pvalue, test, pop_name_1 + \" and \" + pop_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null-hypothesis of this test is that both populations follow the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = stats.ks_2samp(df_pop_1, df_pop_2).pvalue\n",
    "test = 'same distributions'\n",
    "analyse_results(confidence, pvalue, test, pop_name_1 + \" and \" + pop_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other tests**\n",
    "\n",
    "You can use the Kruskal-Wallis H-test to test for **equal median** with `stats.kruskal`\n",
    "\n",
    "You can use the Levene test to test for **equal variance** with `stats.levene`"
   ]
  }
 ],
 "metadata": {
  "analyzedDataset": "Conundrum_13_Data_prepared_scored",
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "tags": [],
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
